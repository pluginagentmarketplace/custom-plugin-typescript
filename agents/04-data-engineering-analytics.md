---
description: Master data engineering, analytics, and business intelligence across 8+ roles including Data Engineer, Data Scientist, Data Analyst, BI Analyst, Machine Learning Engineer, MLOps, and AI Agent development.
capabilities: ["SQL mastery", "Data pipelines (ETL/ELT)", "Data warehousing", "Machine learning", "Statistical analysis", "Business intelligence", "Data visualization", "Big data processing", "Real-time streaming", "Data governance"]
---

# Data Engineering & Analytics

Master data engineering, analytics, and AI/ML across 8+ specialized roles.

## üéØ 8 Specialized Data & Analytics Roles

1. **Data Engineer** - Data pipeline architect
2. **Data Scientist** - ML and statistical modeling
3. **Data Analyst** - Business analytics
4. **BI Analyst** - Business intelligence
5. **Machine Learning Engineer** - ML systems
6. **MLOps Engineer** - ML operations
7. **Analytics Engineer** - Analytics infrastructure
8. **AI Agent Developer** - Autonomous agents

## üìö Learning Pathways

### Path 1: Data Engineering (6-8 months)
```
Week 1-4:    SQL advanced and data modeling
Week 5-8:    ETL/ELT pipeline design
Week 9-12:   Data warehousing (Snowflake, BigQuery)
Week 13-16:  Real-time streaming (Kafka, Spark)
Week 17-20:  Data governance and quality
Week 21-24:  Cloud data services
Week 25-32:  Advanced distributed systems
```

### Path 2: Data Science (6-8 months)
```
Week 1-4:    Python and pandas
Week 5-8:    Statistics and probability
Week 9-12:   Machine learning algorithms
Week 13-16:  Deep learning basics
Week 17-20:  Feature engineering
Week 21-24:  Model deployment
Week 25-32:  Advanced techniques
```

### Path 3: Analytics & BI (6 months)
```
Week 1-4:    SQL and data querying
Week 5-8:    Data visualization
Week 9-12:   Business metrics and KPIs
Week 13-16:  BI tool mastery (Tableau, Power BI)
Week 17-20:  Dashboard design
Week 21-24:  Business intelligence strategy
```

## üõ†Ô∏è Technology Stack

### Data Processing
- Apache Spark
- Apache Flink
- Apache Beam
- Pandas, Polars
- DuckDB

### Data Warehousing
- Snowflake
- BigQuery (GCP)
- Redshift (AWS)
- Azure Synapse
- ClickHouse

### ETL/ELT
- dbt (data build tool)
- Airflow
- Luigi
- Talend
- Informatica

### Streaming
- Apache Kafka
- AWS Kinesis
- Apache Pulsar
- RabbitMQ

### Machine Learning
- scikit-learn
- TensorFlow
- PyTorch
- XGBoost
- LightGBM

### Analytics & BI
- Tableau
- Power BI
- Metabase
- Looker
- QlikView

### Languages & Tools
- Python (primary)
- SQL (advanced)
- Scala
- Java
- R
- Jupyter Notebooks

## üéì Skill Development Areas

### Data Engineering
- [ ] Advanced SQL and optimization
- [ ] ETL/ELT pipeline design
- [ ] Data warehouse schema design
- [ ] Distributed computing (Spark)
- [ ] Real-time streaming
- [ ] Data governance and quality
- [ ] Cloud data platforms
- [ ] Scalability and performance

### Data Science
- [ ] Statistical analysis
- [ ] Machine learning algorithms
- [ ] Feature engineering
- [ ] Model evaluation and selection
- [ ] Deep learning
- [ ] NLP and computer vision
- [ ] Time series analysis
- [ ] A/B testing

### Analytics & BI
- [ ] SQL query optimization
- [ ] Data visualization principles
- [ ] Dashboard design
- [ ] Business metrics
- [ ] Statistical analysis
- [ ] Storytelling with data
- [ ] BI tool expertise
- [ ] Data exploration techniques

## üìä Career Progression

```
Data Analyst ‚Üí Data Engineer ‚Üí Data Architect
Data Analyst ‚Üí Data Scientist ‚Üí ML Engineer ‚Üí ML Lead
Data Analyst ‚Üí Analytics Lead ‚Üí Director of Analytics
```

## üöÄ Quick Start Projects

### Beginner
- [ ] SQL data analysis
- [ ] ETL pipeline with Python
- [ ] Data visualization dashboard
- [ ] Statistical analysis project

### Intermediate
- [ ] End-to-end data pipeline
- [ ] Machine learning model
- [ ] BI dashboard
- [ ] Data warehouse design

### Advanced
- [ ] Real-time analytics system
- [ ] ML serving infrastructure
- [ ] Data governance solution
- [ ] Advanced ML project

## üìñ Best Practices

1. **Data Quality** - Validation and testing
2. **Documentation** - Clear metadata and lineage
3. **Performance** - Query and pipeline optimization
4. **Governance** - Data security and compliance
5. **Monitoring** - Data quality and pipeline alerts
6. **Testing** - Data pipeline testing
7. **Version Control** - Git for all code and configs
8. **Scalability** - Design for growth

## üîó Related Skills

See `skills/data/SKILL.md` for detailed technical guides and code examples.

## üìö Learning Resources

- [SQL Tutorial](https://mode.com/sql-tutorial/)
- [Apache Spark Docs](https://spark.apache.org/docs/)
- [dbt Documentation](https://docs.getdbt.com/)
- [Kaggle](https://www.kaggle.com/)
- [Fast.ai](https://www.fast.ai/)
